{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55dd487-ba3c-4256-ad78-340005ebbe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import optuna as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#from twilio.rest import Client\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "sys.path.append('../../pscapes')\n",
    "sys.path.append('../../nk-ml-2024/')\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pscapes.landscape_class import ProteinLandscape\n",
    "from pscapes.utils import dict_to_np_array, np_array_to_dict\n",
    "\n",
    "from src.architectures import SequenceRegressionCNN, SequenceRegressionLinear, SequenceRegressionMLP, SequenceRegressionLSTM, SequenceRegressionTransformer\n",
    "\n",
    "from src.ml_utils import train_val_test_split_ohe, landscapes_ohe_to_numpy\n",
    "from src.hyperopt import objective_NK, sklearn_objective_NK\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor \n",
    "\n",
    "from src.train_utils import train_models_from_hparams_NK, read_MLP_hparams, read_CNN_hparams, read_LSTM_hparams, read_transformer_hparams, instantiate_model_from_study\n",
    "\n",
    "from src.analysis import get_latent_representation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import math\n",
    "import networkx as nx\n",
    "from scipy.sparse import diags\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.regression import SpearmanCorrCoef, PearsonCorrCoef\n",
    "from src.analysis import adjacency_to_diag_laplacian, sparse_dirichlet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d20e04-75c5-4910-b238-35cdd592d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set global parameters\n",
    "HPARAM_PATH = '../hyperopt/results/NK_hyperopt_results.pkl'\n",
    "DATA_PATH = '../data/nk_landscapes/'\n",
    "MODEL_SAVEPATH = '../models/models_K3/'\n",
    "RESULT_PATH = '../results/results_K3/NK_train_test_results.pkl'\n",
    "SEQ_LEN = 6\n",
    "AA_ALPHABET  = 'ACDEFG'\n",
    "N_REPLICATES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291ff9c6-d5f2-4001-9f29-cdd1bb699e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading landscapes.\n",
      "Calculating train-test-val splits\n"
     ]
    }
   ],
   "source": [
    "#load landscapes\n",
    "#load landscape data \n",
    "landscapes = []\n",
    "print('Loading landscapes.')\n",
    "for k in range(SEQ_LEN):\n",
    "    replicate_list = []\n",
    "    for r in range(N_REPLICATES):\n",
    "        landscape = ProteinLandscape(csv_path=DATA_PATH+'/k{0}_r{1}.csv'.format(k,r), amino_acids=AA_ALPHABET)\n",
    "        replicate_list.append(landscape)\n",
    "    landscapes.append(replicate_list)\n",
    "landscapes = [[i.fit_OHE() for i in j] for j in landscapes]\n",
    "\n",
    "print('Calculating train-test-val splits')\n",
    "splits = [train_val_test_split_ohe(i, random_state=1) for i in landscapes]\n",
    "#landscapes_ohe, xy_train, xy_val, xy_test, x_tests, y_tests = splits[k_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fc00a2-60e9-4df6-bc52-7baf659c9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load hparam studies \n",
    "with open(HPARAM_PATH, 'rb') as handle: \n",
    "    NK_hparams = pickle.load(handle)\n",
    "\n",
    "model_names = ['linear', 'mlp', 'cnn', 'ulstm', 'blstm', 'transformer']\n",
    "NK_hparams_k3 = {x:[NK_hparams[x][3] for _ in range(SEQ_LEN)] for x in NK_hparams.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f75b5-d0ae-4603-b109-b575bb18e7ac",
   "metadata": {},
   "source": [
    "## Implementing Latent Space Regularisation with kNN Dirichlet Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd840b1-9a98-4b5d-a98e-e45238f9952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_utils import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f812ba01-525c-4466-888b-c37b71e47449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633.3333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "49000/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee9cc0-6855-4ae7-9c9a-642b2fe9085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_latent_representationw(model, model_name,  x_data):\n",
    "    # Variable to store the final layer activation\n",
    "    final_activation = None\n",
    "    # Define a forward hook callback function to capture the output\n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal final_activation  # Use nonlocal to modify the variable outside the inner function\n",
    "        final_activation = output\n",
    "\n",
    "    # Attach the hook to the final layer of the model\n",
    "    if model_name == 'mlp': \n",
    "        final_layer = model.fc_layers[-1]\n",
    "        hook_handle = final_layer.register_forward_hook(forward_hook)\n",
    "    elif model_name == 'cnn': \n",
    "        final_layer = list(model.children())[-2] #gets the final MaxPool1d layer \n",
    "        hook_handle = final_layer.register_forward_hook(forward_hook)\n",
    "    elif model_name == 'ulstm' or model_name=='blstm': \n",
    "        hook_handle = model.lstm.register_forward_hook(forward_hook)\n",
    "    elif model_name == 'transformer': \n",
    "        final_layer = list(model.children())[-2] #gets output of Transformer module\n",
    "        hook_handle = final_layer.register_forward_hook(forward_hook)\n",
    "\n",
    "    else: \n",
    "        raise Exception('Model name not recognised.')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Run a forward pass\n",
    "    _ = model(x_data)\n",
    "\n",
    "    # Remove the hook to prevent side effects\n",
    "    hook_handle.remove()\n",
    "\n",
    "    if model_name =='ulstm' or model_name=='blstm': \n",
    "        final_activation = final_activation[0][:, -1, :]\n",
    "    # Return the captured activation\n",
    "    return final_activation.detach()\n",
    "\n",
    "def dirichlet_from_representation(rep_tensor, y_data, degree=30, n_jobs=-1): \n",
    "    \"\"\"\n",
    "    Constructs a kNN graph from the representation of a model, and computes the dirichlet energy of the \n",
    "    signal y over that kNN. \n",
    "    Args: \n",
    "        rep_tensor (torch.tensor):        torch tensor of shape ()\n",
    "        y_data (np.array):                np array containing y_data of shape (n_samples, 1) or (n_samples,)\n",
    "        degree (int):                     degree of the kNN graph\n",
    "    Returns: \n",
    "        dirichlet_energy (float)    \n",
    "    \"\"\"\n",
    "    A = kneighbors_graph(rep_tensor, n_neighbors=degree, n_jobs=n_jobs) #compute adjacency\n",
    "    A = A.maximum(A.T) #ensure A is symmetric \n",
    "    L = adjacency_to_diag_laplacian(A)[1] #compute laplacian \n",
    "    dirichlet_energy = sparse_dirichlet(L, y_data)\n",
    "    \n",
    "    return dirichlet_energy\n",
    "\n",
    "\n",
    "\n",
    "def train_model_de_reg(model, model_name, optimizer, loss_fn, train_loader, val_loader, n_epochs=30, device='cpu', \n",
    "                       patience=5, min_delta=1e-5, lambda_reg=0.1, knn_degree=30, x_data=None):\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n",
    "    model = model.to(device)\n",
    "    val_epoch_losses = []\n",
    "    train_epoch_losses = []\n",
    "    de_epoch_losses = []\n",
    "    epoch_latent_reps  = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()  # Training mode\n",
    "        train_loss = 0.0\n",
    "        de_loss    = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch) #compute primary loss criterion\n",
    "            latent_rep  = get_latent_representationw(model, model_name, x_batch) #compute dirichlet energy on train_data\n",
    "            de = dirichlet_from_representation(latent_rep, y_batch, degree=knn_degree, n_jobs=-1) #compute dirichlet energy of this batch's knn\n",
    "            \n",
    "            total_loss = loss + lambda_reg * de\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            de_loss += de.item()\n",
    "            \n",
    "        epoch_loss = train_loss/len(train_loader)\n",
    "        de_epoch_loss = de_loss/len(train_loader)\n",
    "        train_epoch_losses.append(epoch_loss)\n",
    "        de_epoch_losses.append(de_epoch_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                #print(inputs.shape)\n",
    "                #print(targets.shape)\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_epoch_losses.append(val_loss)\n",
    "\n",
    "        assert x_data!=None, 'No landscape x_data provided for latent representation calculation.'\n",
    "        x_data = x_data.to(device)\n",
    "        latent_rep  = get_latent_representation(model, model_name, x_data)\n",
    "        epoch_latent_reps.append(latent_rep)\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Check early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Load the best model after early stopping\n",
    "    model.load_state_dict(torch.load(early_stopping.path))\n",
    "    return model, train_epoch_losses, val_epoch_losses, epoch_latent_reps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
