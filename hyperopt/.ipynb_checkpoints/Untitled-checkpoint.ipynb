{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6332878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahakaran/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/mahakaran/NK-paper-12-5-24-version/nk-ml-paper2-2024/pscapes')\n",
    "sys.path.append('/home/mahakaran/NK-paper-12-5-24-version/nk-ml-paper2-2024/nk-ml-2024')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pscapes.landscape_class import ProteinLandscape\n",
    "from pscapes.utils import dict_to_np_array, np_array_to_dict\n",
    "\n",
    "from src.architectures.architectures import SequenceRegressionCNN\n",
    "from src.architectures.ml_utils import train_val_test_split_ohe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da33e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ProteinLandscape(csv_path='../data/nk_landscapes/k0_r0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ef1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 6\n",
    "AA_ALPHABET = 'ACDEFG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013312c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load NK landscapes -- only a single replicate for hparam tuning \n",
    "\n",
    "LANDSCAPES = []\n",
    "for k in range(6): \n",
    "    for r in range(1): \n",
    "        landscape = ProteinLandscape(csv_path='../data/nk_landscapes/k{0}_r{1}.csv'.format(k,r), amino_acids=AA_ALPHABET)\n",
    "        LANDSCAPES.append(landscape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcc4672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDSCAPES = [i.fit_OHE() for i in LANDSCAPES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed04997",
   "metadata": {},
   "outputs": [],
   "source": [
    "landscapes_ohe, xy_train, xy_val, xy_test, x_test, y_test = train_val_test_split_ohe(LANDSCAPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f627366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec3deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape0_xy_train = xy_train[0]\n",
    "landscape0_xy_val   = xy_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e14f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_objective(trial, train_data, val_data, epochs):\n",
    "    # Define the search space\n",
    "    num_conv_layers = trial.suggest_int('num_conv_layers', 1, 2)\n",
    "    \n",
    "    num_kernels = [int(trial.suggest_discrete_uniform(\"n_kernels\", 16, 128, 16))\n",
    "                   for i in range(num_conv_layers)]  \n",
    "    \n",
    "    kernel_sizes = [int(trial.suggest_discrete_uniform(\"kernel_sizes\", 2, 6, 1))\n",
    "                   for i in range(num_conv_layers)]\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
    "\n",
    "    \n",
    "    # Initialize model with the trialâ€™s hyperparameters\n",
    "    model = SequenceRegressionCNN(input_channels=len(AA_ALPHABET), sequence_length=SEQ_LEN, \n",
    "                                  num_conv_layers=num_conv_layers, n_kernels=num_kernels, kernel_sizes=kernel_sizes)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Dummy training and validation data loaders\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "    # Training loop with validation loss calculation\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(x_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate validation loss\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                predictions = model(x_batch)\n",
    "                val_loss += loss_fn(predictions, y_batch).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        \n",
    "        trial.report(val_loss, epoch)\n",
    "        \n",
    "        print('Epoch {0}: Val loss: {1}'.format(epoch, val_loss))\n",
    "        if trial.should_prune():\n",
    "            raise opt.TrialPruned()\n",
    "    print('Best Val Loss this Trial: {}'.format(val_loss))\n",
    "        \n",
    "\n",
    "    return val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b667d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 14:06:41,565] A new study created in memory with name: no-name-8ac769ad-c53e-4813-be97-0e7da7429801\n",
      "/tmp/ipykernel_57346/1706552619.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  num_kernels = [int(trial.suggest_discrete_uniform(\"n_kernels\", 16, 128, 16))\n",
      "/tmp/ipykernel_57346/1706552619.py:8: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  kernel_sizes = [int(trial.suggest_discrete_uniform(\"kernel_sizes\", 2, 6, 1))\n",
      "/tmp/ipykernel_57346/1706552619.py:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Val loss: 6.406040604341462e-05\n",
      "Epoch 1: Val loss: 4.176465309628994e-05\n",
      "Epoch 2: Val loss: 9.847667383721087e-05\n",
      "Epoch 3: Val loss: 9.482124142257226e-05\n",
      "Epoch 4: Val loss: 0.00035426035777389066\n",
      "Epoch 5: Val loss: 4.105059404412939e-05\n",
      "Epoch 6: Val loss: 1.9745306289200344e-05\n",
      "Epoch 7: Val loss: 0.00012022573775119291\n",
      "Epoch 8: Val loss: 0.00016489610412759054\n",
      "Epoch 9: Val loss: 5.594520910710701e-05\n",
      "Epoch 10: Val loss: 7.92523748255668e-06\n",
      "Epoch 11: Val loss: 8.808666532584337e-06\n",
      "Epoch 12: Val loss: 2.5608373503835024e-05\n",
      "Epoch 13: Val loss: 3.0780139147678616e-05\n",
      "Epoch 14: Val loss: 8.668159688195141e-06\n",
      "Epoch 15: Val loss: 6.758396217715677e-06\n",
      "Epoch 16: Val loss: 3.4161279371700302e-06\n",
      "Epoch 17: Val loss: 1.4736767581749347e-05\n",
      "Epoch 18: Val loss: 7.72482529559305e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 14:07:10,094] Trial 0 finished with value: 3.0381646974690848e-05 and parameters: {'num_conv_layers': 1, 'n_kernels': 48.0, 'kernel_sizes': 3.0, 'lr': 0.007937900803106161}. Best is trial 0 with value: 3.0381646974690848e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Val loss: 3.0381646974690848e-05\n",
      "Best Val Loss this Trial: 3.0381646974690848e-05\n",
      "Epoch 0: Val loss: 6.714870462143837e-05\n",
      "Epoch 1: Val loss: 3.147456439745659e-05\n",
      "Epoch 2: Val loss: 3.760856170396064e-05\n",
      "Epoch 3: Val loss: 7.373076601248208e-05\n",
      "Epoch 4: Val loss: 2.4670104989920033e-05\n",
      "Epoch 5: Val loss: 0.00038600036450044817\n",
      "Epoch 6: Val loss: 6.347357755766696e-05\n",
      "Epoch 7: Val loss: 7.451704842758337e-05\n",
      "Epoch 8: Val loss: 4.652663170014016e-05\n",
      "Epoch 9: Val loss: 4.4064754664036744e-05\n",
      "Epoch 10: Val loss: 6.939456043488835e-05\n",
      "Epoch 11: Val loss: 4.541923294904041e-05\n",
      "Epoch 12: Val loss: 5.23121076558033e-05\n",
      "Epoch 13: Val loss: 4.859091165373808e-05\n",
      "Epoch 14: Val loss: 2.7224153141921703e-05\n",
      "Epoch 15: Val loss: 1.0878249668166973e-05\n",
      "Epoch 16: Val loss: 3.844023312067137e-05\n",
      "Epoch 17: Val loss: 4.7155799022112063e-05\n",
      "Epoch 18: Val loss: 4.997321396245737e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 14:07:39,553] Trial 1 finished with value: 1.972890336569085e-05 and parameters: {'num_conv_layers': 1, 'n_kernels': 80.0, 'kernel_sizes': 3.0, 'lr': 0.003995010349141688}. Best is trial 1 with value: 1.972890336569085e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Val loss: 1.972890336569085e-05\n",
      "Best Val Loss this Trial: 1.972890336569085e-05\n",
      "Epoch 0: Val loss: 0.00019037667385792025\n",
      "Epoch 1: Val loss: 0.00011469984173555321\n",
      "Epoch 2: Val loss: 0.00013418510146342064\n",
      "Epoch 3: Val loss: 4.608148594700799e-05\n",
      "Epoch 4: Val loss: 3.7943334763650244e-05\n",
      "Epoch 5: Val loss: 2.465340244232052e-05\n",
      "Epoch 6: Val loss: 4.051496047100239e-05\n",
      "Epoch 7: Val loss: 4.2423117294799114e-05\n",
      "Epoch 8: Val loss: 1.7811806208975704e-05\n",
      "Epoch 9: Val loss: 1.894223569213195e-05\n",
      "Epoch 10: Val loss: 2.9350058555901032e-05\n",
      "Epoch 11: Val loss: 2.1172472599542572e-05\n",
      "Epoch 12: Val loss: 3.161781414668921e-05\n",
      "Epoch 13: Val loss: 9.061573018309582e-06\n",
      "Epoch 14: Val loss: 3.015259971239447e-05\n",
      "Epoch 15: Val loss: 1.8839253189226783e-05\n",
      "Epoch 16: Val loss: 3.5516843531190214e-05\n",
      "Epoch 17: Val loss: 8.478370029137233e-06\n",
      "Epoch 18: Val loss: 2.401197695075813e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 14:08:11,108] Trial 2 finished with value: 6.643139340473067e-06 and parameters: {'num_conv_layers': 1, 'n_kernels': 96.0, 'kernel_sizes': 6.0, 'lr': 0.0014317493546176436}. Best is trial 2 with value: 6.643139340473067e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Val loss: 6.643139340473067e-06\n",
      "Best Val Loss this Trial: 6.643139340473067e-06\n",
      "Epoch 0: Val loss: 8.14648547098359e-05\n",
      "Epoch 1: Val loss: 6.227283236699011e-05\n",
      "Epoch 2: Val loss: 0.00018548760051330607\n",
      "Epoch 3: Val loss: 0.0009451223821896645\n",
      "Epoch 4: Val loss: 9.428260896556899e-05\n",
      "Epoch 5: Val loss: 0.00010445143603786934\n",
      "Epoch 6: Val loss: 8.321416826842105e-05\n",
      "Epoch 7: Val loss: 4.101877010935613e-05\n",
      "Epoch 8: Val loss: 0.0005381829133923922\n",
      "Epoch 9: Val loss: 7.950938915877114e-05\n",
      "Epoch 10: Val loss: 3.865462208406639e-05\n",
      "Epoch 11: Val loss: 5.080973461835494e-05\n",
      "Epoch 12: Val loss: 3.0308902210875116e-05\n",
      "Epoch 13: Val loss: 7.839101881550478e-05\n",
      "Epoch 14: Val loss: 2.5489551934984993e-05\n",
      "Epoch 15: Val loss: 2.3654287629025744e-05\n",
      "Epoch 16: Val loss: 9.45714548787435e-06\n",
      "Epoch 17: Val loss: 1.5144759353049274e-05\n",
      "Epoch 18: Val loss: 1.454991589082802e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 14:08:44,076] Trial 3 finished with value: 8.758992328142233e-06 and parameters: {'num_conv_layers': 1, 'n_kernels': 128.0, 'kernel_sizes': 3.0, 'lr': 0.006593503188757435}. Best is trial 2 with value: 6.643139340473067e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Val loss: 8.758992328142233e-06\n",
      "Best Val Loss this Trial: 8.758992328142233e-06\n",
      "Epoch 0: Val loss: 0.00012651164264457487\n",
      "Epoch 1: Val loss: 9.711930670941639e-05\n",
      "Epoch 2: Val loss: 0.0004594406113277277\n",
      "Epoch 3: Val loss: 3.626803363736572e-05\n",
      "Epoch 4: Val loss: 2.7196575742852714e-05\n",
      "Epoch 5: Val loss: 3.240114809656924e-05\n",
      "Epoch 6: Val loss: 1.234732653018031e-05\n",
      "Epoch 7: Val loss: 0.000327718949629965\n",
      "Epoch 8: Val loss: 1.922550492388401e-05\n",
      "Epoch 9: Val loss: 3.92787501252128e-05\n",
      "Epoch 10: Val loss: 1.705682584581823e-05\n",
      "Epoch 11: Val loss: 3.872261003512266e-05\n",
      "Epoch 12: Val loss: 4.976849997438277e-05\n",
      "Epoch 13: Val loss: 3.6450479994419166e-06\n",
      "Epoch 14: Val loss: 1.4094836749278236e-05\n",
      "Epoch 15: Val loss: 3.8226357015119924e-05\n",
      "Epoch 16: Val loss: 5.8462458059888085e-06\n",
      "Epoch 17: Val loss: 0.0005680326622130716\n",
      "Epoch 18: Val loss: 5.805614725828397e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-28 14:09:32,497] Trial 4 finished with value: 4.294698210948351e-06 and parameters: {'num_conv_layers': 2, 'n_kernels': 32.0, 'kernel_sizes': 4.0, 'lr': 0.008745368120211164}. Best is trial 4 with value: 4.294698210948351e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Val loss: 4.294698210948351e-06\n",
      "Best Val Loss this Trial: 4.294698210948351e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-28 14:09:34,487] Trial 5 failed with parameters: {'num_conv_layers': 1, 'n_kernels': 32.0, 'kernel_sizes': 2.0, 'lr': 0.0008018973793972665} because of the following error: NameError(\"name 'optuna' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mahakaran/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_57346/1125805103.py\", line 5, in <lambda>\n",
      "    cnn_study.optimize(lambda trial: cnn_objective(trial, train_data=landscape0_xy_train, val_data=landscape0_xy_val,\n",
      "  File \"/tmp/ipykernel_57346/1706552619.py\", line 53, in cnn_objective\n",
      "    raise optuna.TrialPruned()\n",
      "NameError: name 'optuna' is not defined\n",
      "[W 2024-10-28 14:09:34,489] Trial 5 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Val loss: 0.0032401715771446372\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Running the study\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cnn_study \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m cnn_study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: cnn_objective(trial, train_data\u001b[38;5;241m=\u001b[39mlandscape0_xy_train, val_data\u001b[38;5;241m=\u001b[39mlandscape0_xy_val, \n\u001b[1;32m      6\u001b[0m                                 epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest CNN hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cnn_study\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest CNN validation loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cnn_study\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [14], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Running the study\u001b[39;00m\n\u001b[1;32m      2\u001b[0m cnn_study \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m cnn_study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mcnn_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlandscape0_xy_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlandscape0_xy_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest CNN hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cnn_study\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest CNN validation loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cnn_study\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "Cell \u001b[0;32mIn [13], line 53\u001b[0m, in \u001b[0;36mcnn_objective\u001b[0;34m(trial, train_data, val_data, epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m: Val loss: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, val_loss))\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trial\u001b[38;5;241m.\u001b[39mshould_prune():\n\u001b[0;32m---> 53\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43moptuna\u001b[49m\u001b[38;5;241m.\u001b[39mTrialPruned()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Val Loss this Trial: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(val_loss))\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_loss\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "# Running the study\n",
    "cnn_study = opt.create_study(direction=\"minimize\")\n",
    "\n",
    "\n",
    "cnn_study.optimize(lambda trial: cnn_objective(trial, train_data=landscape0_xy_train, val_data=landscape0_xy_val, \n",
    "                                epochs=20), n_trials=50)\n",
    "\n",
    "print(\"Best CNN hyperparameters:\", cnn_study.best_params)\n",
    "print(\"Best CNN validation loss:\", cnn_study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SequenceRegressionCNN(num_conv_layers=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
